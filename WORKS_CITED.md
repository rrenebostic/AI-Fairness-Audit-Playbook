## AI Fairness Audit Playbook 

## Works Cited ##

Agarwal, Neha, et al. "Mitigating Bias in Machine Learning Using Confidence Intervals for Fairness Metrics." Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, 2021, pp. 23-34, https://dl.acm.org/doi/10.1145/3461702.3462533.

Anthropic. Claude 4 Sonnet, 2025, https://claude.ai. Large language model.

Barocas, Solon, et al. Fairness and Machine Learning: Limitations and Opportunities, 2019, https://fairmlbook.org/.

Buolamwini, Joy, and Timnit Gebru. "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification." Proceedings of the 1st Conference on Fairness, Accountability, and Transparency, 2018, pp. 77-91, https://proceedings.mlr.press/v81/buolamwini18a.html.

Chouldechova, Alexandra. "Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments." Big Data, vol. 5, no. 2, 2017, pp. 153-163, https://doi.org/10.1089/big.2016.0047.

D'Amour, Alexander, et al. "Fairness Is Not Static: Deeper Understanding of Long Term Fairness via Simulation Studies." Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 2020, pp. 525-534, https://dl.acm.org/doi/10.1145/3351095.3372878.

Dwork, Cynthia, et al. "Fairness Through Awareness." Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, 2012, pp. 214-226, https://doi.org/10.1145/2090236.2090255.

Ekstrand, Michael D., et al. "All the Cool Kids, How Do They Fit In?: Popularity and Demographic Biases in Recommender Evaluation and Effectiveness." Proceedings of the 1st Conference on Fairness, Accountability and Transparency, 2018, pp. 172-186, https://proceedings.mlr.press/v81/ekstrand18b.html.

Ensign, Danielle, et al. "Runaway Feedback Loops in Predictive Policing." Proceedings of the 1st Conference on Fairness, Accountability and Transparency, 2018, pp. 160-171, https://proceedings.mlr.press/v81/ensign18a.html.

Friedler, Sorelle A., et al. "A Comparative Study of Fairness-Enhancing Interventions in Machine Learning." Proceedings of the Conference on Fairness, Accountability, and Transparency, 2019, pp. 329-338, https://dl.acm.org/doi/10.1145/3287560.3287589.

Hardt, Moritz, et al. "Equality of Opportunity in Supervised Learning." Advances in Neural Information Processing Systems, 2016, pp. 3315-3323, https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf.

Hashimoto, Tatsunori B., et al. "Fairness Without Demographics in Repeated Loss Minimization." Proceedings of the 35th International Conference on Machine Learning, 2018, pp. 1929-1938, https://proceedings.mlr.press/v80/hashimoto18a.html.

Holstein, Kenneth, et al. "Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?" Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, 2019, pp. 1-16, https://doi.org/10.1145/3290605.3300830.

Ilvento, Christina. "Metric Learning for Individual Fairness." arXiv, 2019, https://arxiv.org/abs/1906.00250.

Kearns, Michael, et al. "Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness." International Conference on Machine Learning, 2018, pp. 2564-2572, https://proceedings.mlr.press/v80/kearns18a.html.

Kleinberg, Jon, et al. "Inherent Trade-Offs in the Fair Determination of Risk Scores." arXiv, 2016, https://arxiv.org/abs/1609.05807.

Kusner, Matt J., et al. "Counterfactual Fairness." Advances in Neural Information Processing Systems, 2017, pp. 4066-4076.

Madaio, Michael A., et al. "Co-Designing Checklists to Understand Organizational Challenges and Opportunities Around Fairness in AI." Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 2020, pp. 1-14, https://doi.org/10.1145/3313831.3376445.

Mansoury, Masoud, et al. "Feedback Loop and Bias Amplification in Recommender Systems." Proceedings of the 29th ACM International Conference on Information & Knowledge Management, 2020, pp. 2145-2148, https://dl.acm.org/doi/10.1145/3340531.3412152.

Napkin AI. Napkin AI, 2025, https://napkin.ai. AI-powered visual communication platform.

Ogbonnaya-Ogburu, Ihudiya Finda, et al. "Critical Race Theory for HCI." Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 2020, pp. 1-16, https://doi.org/10.1145/3313831.3376392.

O'Neil, Cathy. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown Publishing Group, 2016.

Sambasivan, Nithya, et al. "'Everyone Wants to Do the Model Work, Not the Data Work': Data Cascades in High-Stakes AI." Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 2021, pp. 1-15, https://doi.org/10.1145/3411764.3445518.

Selbst, Andrew D., et al. "Fairness and Abstraction in Sociotechnical Systems." Proceedings of the Conference on Fairness, Accountability, and Transparency, 2019, pp. 59-68, https://doi.org/10.1145/3287560.3287598.

Suresh, Harini, and John V. Guttag. "A Framework for Understanding Sources of Harm Throughout the Machine Learning Life Cycle." Equity and Access in Algorithms, Mechanisms, and Optimization, 2021, pp. 1-9, https://dl.acm.org/doi/10.1145/3465416.3483305.

"The Power of Authenticity: Embracing True Self over Performative Acts." NBMBAA, National Black MBA Association, nbmbaa.org/the-power-of-authenticity-embracing-true-self-over-performative-acts/. Accessed 25 Sept. 2025.

Veale, Michael, and Reuben Binns. "Fairer Machine Learning in the Real World: Mitigating Discrimination Without Collecting Sensitive Data." Big Data & Society, vol. 4, no. 2, 2017, pp. 2053951717743530, https://doi.org/10.1177/2053951717743530.

Veale, Michael, et al. "Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making." Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 2018, pp. 1-14, https://doi.org/10.1145/3173574.3174014.

Wachter, Sandra, et al. "Why Fairness Cannot Be Automated: Bridging the Gap Between EU Non-Discrimination Law and AI." Computer Law & Security Review, vol. 41, 2021, pp. 105567, https://doi.org/10.1016/j.clsr.2021.105567.

Yang, Kai, et al. "Towards Fairer Datasets: Filtering and Balancing the Distribution of the People Subtree in the ImageNet Hierarchy." Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 2020, pp. 547-558, https://dl.acm.org/doi/10.1145/3351095.3375709.

Yang, Qian, et al. "Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design." Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 2020, pp. 1-13, https://doi.org/10.1145/3313831.3376301.

Zhang, Jingchen, and Jessica Walsh. "Bootstrap Confidence Intervals for Fairness Metrics." Journal of Statistical Computation and Simulation, vol. 91, no. 16, 2021, pp. 3225-3244, https://doi.org/10.1080/00949655.2021.1913218.
